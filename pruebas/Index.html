<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection</title>
</head>
<body>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
                video.srcObject = stream;
            } catch (error) {
                console.error('Error al acceder a la cámara: ', error);
            }
        }

        startVideo();

        async function sendFrame(frame) {
            const websocket = new WebSocket('ws://localhost:8080');

            websocket.onopen = () => {
                console.log('Conexión establecida con el servidor');
                websocket.send(frame);
            };

            websocket.onmessage = (event) => {
                const detectedFaces = JSON.parse(event.data);
                console.log('Caras detectadas: ', detectedFaces);
                // Aquí puedes procesar y mostrar las caras detectadas en el canvas
            };

            websocket.onclose = () => {
                console.log('Conexión cerrada con el servidor');
            };
        }

        function captureFrame() {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const frame = canvas.toDataURL('image/jpeg');
            sendFrame(frame);
        }

        setInterval(captureFrame, 1000); // Capturar y enviar un frame cada segundo
    </script>
</body>
</html>
